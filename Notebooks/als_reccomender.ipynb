{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pyspark","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LoTDsYofmjuE","outputId":"fea8f7f3-bce6-4b8d-811d-2c59e8c2d369","execution":{"iopub.status.busy":"2023-09-10T03:23:42.111072Z","iopub.execute_input":"2023-09-10T03:23:42.111515Z","iopub.status.idle":"2023-09-10T03:24:37.507638Z","shell.execute_reply.started":"2023-09-10T03:23:42.111481Z","shell.execute_reply":"2023-09-10T03:24:37.506293Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting pyspark\n  Downloading pyspark-3.4.1.tar.gz (310.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: py4j==0.10.9.7 in /opt/conda/lib/python3.10/site-packages (from pyspark) (0.10.9.7)\nBuilding wheels for collected packages: pyspark\n  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.4.1-py2.py3-none-any.whl size=311285398 sha256=0582addfa925fbf7bf5bd08a3b1bbcd8de4d92a218332699823c7b5206c080c6\n  Stored in directory: /root/.cache/pip/wheels/0d/77/a3/ff2f74cc9ab41f8f594dabf0579c2a7c6de920d584206e0834\nSuccessfully built pyspark\nInstalling collected packages: pyspark\nSuccessfully installed pyspark-3.4.1\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sklearn\nimport random\nimport os\nfrom pyspark.sql import SparkSession\nfrom pyspark.ml.recommendation import ALS, ALSModel\nimport pyspark.sql.functions as F","metadata":{"id":"1F_ll7Jemlyi","execution":{"iopub.status.busy":"2023-09-10T03:24:37.510316Z","iopub.execute_input":"2023-09-10T03:24:37.511065Z","iopub.status.idle":"2023-09-10T03:24:39.174387Z","shell.execute_reply.started":"2023-09-10T03:24:37.511020Z","shell.execute_reply":"2023-09-10T03:24:39.172969Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"RANDOM_SEED = 42\npath = '/kaggle/input/rutube-data/'\nsave_path = '/kaggle/working/'","metadata":{"id":"-p30PMyLm1Gz","execution":{"iopub.status.busy":"2023-09-10T03:24:39.176132Z","iopub.execute_input":"2023-09-10T03:24:39.176721Z","iopub.status.idle":"2023-09-10T03:24:39.181966Z","shell.execute_reply.started":"2023-09-10T03:24:39.176657Z","shell.execute_reply":"2023-09-10T03:24:39.180800Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"spark = SparkSession.builder \\\n    .master('local[*]') \\\n    .config(\"spark.driver.memory\", \"15g\") \\\n    .appName('Recommender_system') \\\n    .getOrCreate()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":321},"id":"I1ULZ66dmq7L","outputId":"482dd257-3010-4646-f041-c18e8846d086","execution":{"iopub.status.busy":"2023-09-10T03:24:39.184775Z","iopub.execute_input":"2023-09-10T03:24:39.185151Z","iopub.status.idle":"2023-09-10T03:24:45.826987Z","shell.execute_reply.started":"2023-09-10T03:24:39.185121Z","shell.execute_reply":"2023-09-10T03:24:45.825913Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"Setting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n23/09/10 03:24:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n","output_type":"stream"}]},{"cell_type":"code","source":"interactions = spark.read.parquet(f\"{path}player_starts_train.parquet\").select('date', 'user_id', 'item_id', 'watch_time')\nvideos = spark.read.parquet(f\"{path}videos.parquet\").withColumn('duration', F.col('duration')/1000)\nvideos = videos.select('duration', 'item_id')\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":339},"id":"yoi5d11YmtBI","outputId":"79fc6c38-4784-4354-f6ec-eb82bd62859a","execution":{"iopub.status.busy":"2023-09-10T03:24:45.828294Z","iopub.execute_input":"2023-09-10T03:24:45.828656Z","iopub.status.idle":"2023-09-10T03:24:52.549176Z","shell.execute_reply.started":"2023-09-10T03:24:45.828623Z","shell.execute_reply":"2023-09-10T03:24:52.547944Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"# interactions.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":321},"id":"Koftl5spm8Ye","outputId":"78494e12-8a62-4aa8-af94-59bc973ba8b6","execution":{"iopub.status.busy":"2023-09-10T03:24:52.550510Z","iopub.execute_input":"2023-09-10T03:24:52.552662Z","iopub.status.idle":"2023-09-10T03:24:52.562093Z","shell.execute_reply.started":"2023-09-10T03:24:52.552614Z","shell.execute_reply":"2023-09-10T03:24:52.560896Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# videos.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"82dd9-2jnFVL","outputId":"1dc4158f-a062-485d-b5ae-409098b9630e","execution":{"iopub.status.busy":"2023-09-10T03:24:52.563277Z","iopub.execute_input":"2023-09-10T03:24:52.563734Z","iopub.status.idle":"2023-09-10T03:24:52.570556Z","shell.execute_reply.started":"2023-09-10T03:24:52.563673Z","shell.execute_reply":"2023-09-10T03:24:52.569359Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"join_interactions = interactions.join(videos,\n                                      on='item_id',\n                                      how='inner')\njoin_interactions = join_interactions.withColumn('norm_watch_time', F.col('watch_time')/F.col('duration'))\njoin_interactions = join_interactions.withColumn('item_id', F.regexp_replace(\"item_id\", \"video_\", \"\").cast('integer'))\njoin_interactions = join_interactions.withColumn('user_id', F.regexp_replace(\"user_id\", \"user_\", \"\").cast('integer'))\njoin_interactions = join_interactions.na.fill(value=0,subset=[\"norm_watch_time\"]).select('norm_watch_time', \n                                                                                         'user_id', \n                                                                                         'item_id')","metadata":{"id":"ljROpw-0nGi_","execution":{"iopub.status.busy":"2023-09-10T03:24:52.572415Z","iopub.execute_input":"2023-09-10T03:24:52.573578Z","iopub.status.idle":"2023-09-10T03:24:52.812192Z","shell.execute_reply.started":"2023-09-10T03:24:52.573534Z","shell.execute_reply":"2023-09-10T03:24:52.811216Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# train_data = join_interactions.filter(F.col('date') <= '2023-08-20')\n# test_data = join_interactions.filter(F.col('date') > '2023-08-20')","metadata":{"id":"Hcul7RvxnnoO","execution":{"iopub.status.busy":"2023-09-10T03:24:52.813233Z","iopub.execute_input":"2023-09-10T03:24:52.813540Z","iopub.status.idle":"2023-09-10T03:24:52.820387Z","shell.execute_reply.started":"2023-09-10T03:24:52.813514Z","shell.execute_reply":"2023-09-10T03:24:52.818870Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# print(\"Number of rows in train_data:\", train_data.count())\n# print(\"Number of rows in test_data:\", test_data.count())","metadata":{"id":"p0pXwFF0nyrP","execution":{"iopub.status.busy":"2023-09-10T03:24:52.825386Z","iopub.execute_input":"2023-09-10T03:24:52.825868Z","iopub.status.idle":"2023-09-10T03:24:52.833128Z","shell.execute_reply.started":"2023-09-10T03:24:52.825806Z","shell.execute_reply":"2023-09-10T03:24:52.832142Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Build the recommendation model using ALS on the training data\nals = ALS(maxIter=15, regParam=0.01, userCol=\"user_id\" ,itemCol=\"item_id\", ratingCol=\"norm_watch_time\")\n#Fit the Model on Item-Based Data\nmodel = als.fit(join_interactions)","metadata":{"id":"hMKu2G8bnaYC","execution":{"iopub.status.busy":"2023-09-10T03:24:52.835556Z","iopub.execute_input":"2023-09-10T03:24:52.836640Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"23/09/10 03:29:30 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n23/09/10 03:30:13 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n[Stage 31:===================================================>     (9 + 1) / 10]\r","output_type":"stream"}]},{"cell_type":"code","source":"model.write().save('saved_model')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = ALSModel.load(f'{save_path}saved_model')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"users = spark.read.csv(f'{path}/sample_submission.csv', header=True).withColumn('user_id', \n                                                                        F.regexp_replace(\"user_id\", \n                                                                                         \"user_\", \"\").cast('integer'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"users.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dfs_rec = model.recommendForUserSubset(users.select('user_id'), 10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dfs_rec.select('user_id', F.col('recommendations.item_id').alias('recs')).show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_final = dfs_rec.select('user_id', F.col('recommendations.item_id').alias('recs')).toPandas()\n# df_final.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}